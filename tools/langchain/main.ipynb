{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extending Workshop Learnings: From Supabase and PGvector to LangChain"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://blog.artisanlabs.io/_next/image?url=%2Fassets%2Fblog%2Fpgvector%2Farpagon__dynamic_scene_of_a_PostgreSQL_logo_surrounded_by_float_97e46d53-b243-40ac-b983-19065c16f515.png&w=1920&q=75)\n",
        "\n",
        "[![Twitter URL](https://img.shields.io/twitter/url/https/twitter.com/arpagon.svg?style=social&label=Follow%20%40arpagon)](https://twitter.com/arpagon)\n",
        "\n",
        "Workshop: https://www.ai.engineer/summit/schedule/workshop-supabase\n",
        "\n",
        "Github: https://github.com/supabase-community/chatgpt-your-files/\n",
        "\n",
        "Our Githu: https://github.com/ArtisanLabs/chatgpt-your-files/  \n",
        "\n",
        "## Introduction\n",
        "\n",
        "In today's fast-paced world of technological innovation, AI engineers need to stay up-to-date on the latest tools and frameworks. This was the central theme of the AI Engineer Summit held from October 8-10, 2023, in San Francisco, California. The summit brought together thought leaders, industry veterans, and budding engineers, all united by their passion for artificial intelligence.\n",
        "\n",
        "One workshop that stood out was \"Pgvector to Prod in 2 hours.\" The title was both ambitious and exciting: could we build a production-ready web app in just two hours? I was curious to find out, so I signed up for the workshop.\n",
        "\n",
        "The workshop was led by Greg Richardson, an expert on Supabase and PGvector. He showed us how to use these technologies to create a secure, production-ready web app. The atmosphere in the room was electric as everyone logged into their Supabase accounts and got ready to code.\n",
        "\n",
        "The workshop was more than just a tutorial; it was a journey through the future of AI applications. As we wrote each line of code, we were not only building a web app but also taking a step closer to answering a pressing question: how can we build AI applications quickly and easily, while still maintaining control over our tech stack?\n",
        "\n",
        "In the following sections, I'll share some of the key takeaways from the workshop and how it has inspired me to explore beyond conventional boundaries and venture into a new project with LangChain. So let's embark on this journey and learn how to build AI applications quickly and easily.\n",
        "\n",
        "\n",
        "## Motivation\n",
        "\n",
        "Diving into the world of Supabase and PGvector through the \"Pgvector to Prod in 2 hours\" workshop wasn’t a fluke, but a calculated venture. I already had a solid footing in the realm of Artificial Intelligence with LangChain, but as they say, comparison is a great avenue for learning.\n",
        "\n",
        "I had crafted a Retrieval Augmented Generation (RAG) system with LangChain that has been in production since February. I knew its intricacies and was quite comfortable with what LangChain could offer. So why attend this workshop?\n",
        "\n",
        "The answer is straightforward: I wanted to see how other tools and approaches compared to what I had already accomplished. Supabase and PGvector were quickly gaining ground in the AI community, and I wanted to see what the buzz was about, and more importantly, how they compared to LangChain in terms of facilitating rapid AI application development.\n",
        "\n",
        "Greg Richardson, with his well-earned reputation, leading the workshop, was an additional invitation to dip into these new waters. He promised an intensive session where we could get a functioning MVP (Minimum Viable Product) up and running in merely two hours. That’s something I couldn't pass up.\n",
        "\n",
        "So, with a blend of curiosity and a desire to learn by contrast, I plunged into the workshop. I was ready to see how the technologies discussed in the workshop compared to my experience with LangChain, and if there was anything new and exciting I could bring to my own AI development table.\n",
        "\n",
        "In the following sections, I'll share how this workshop not only met my expectations but also led me to explore and better understand the differences and similarities between the tools, and how these experiences have enriched my perspective on AI application development.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x-tGq9wGry2r"
      },
      "source": [
        "## Create Embedings"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary of Step 3 - Embeddings WorkShop\n",
        "\n",
        "WorkShop: [Step 3 - Embeddings](https://github.com/supabase-community/chatgpt-your-files/blob/main/README.md#step-3---embeddings)\n",
        "\n",
        "In Step 3 titled \"Embeddings,\" the objective is to automate the generation of embeddings whenever new rows are added to the document_sections table. Here’s a summarized breakdown of the step:\n",
        "\n",
        "    Creating SQL Migration:\n",
        "        A migration file is created using the command npx supabase migration new embed.\n",
        "        An embed() trigger function is defined which will be used to asynchronously generate embeddings on arbitrary tables using a new embed Edge Function.\n",
        "\n",
        "    Setting Up Trigger:\n",
        "        A trigger named embed_document_sections is created to execute the embed() function after an insert operation on the document_sections table.\n",
        "\n",
        "    Applying Migration:\n",
        "        The migration is applied to the local database using the command npx supabase migration up.\n",
        "\n",
        "    Creating Edge Function:\n",
        "        An Edge function file is created using the command npx supabase functions new embed.\n",
        "        In the embed/index.ts file, an embedding pipeline is created using Transformers.js, and a function to generate embeddings, generateEmbedding, is defined.\n",
        "\n",
        "    Configuring Supabase Client:\n",
        "        Environment variables for Supabase are checked, and a Supabase client is created.\n",
        "        The Supabase client is configured to inherit the user’s permissions.\n",
        "\n",
        "    Fetching, Generating, and Updating Embeddings:\n",
        "        Text content is fetched from the specified table and column.\n",
        "        Embeddings are generated for each piece of text.\n",
        "        The respective rows in the table are updated with the generated embeddings.\n",
        "\n",
        "    Returning Success Response:\n",
        "        A success response with status 204 is returned upon successful execution of the embedding generation and updating process.\n",
        "\n",
        "This step is crucial as it sets up the necessary infrastructure for automatically generating and storing embeddings, which is a foundational aspect of making the chat interface interactive and efficient in handling document queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GwkUKHmWry2s"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "from langchain.schema import Document\n",
        "from langchain.vectorstores import SupabaseVectorStore\n",
        "from supabase.client import create_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "env_path = Path('.') / '../../.env.local'\n",
        "load_dotenv(dotenv_path=env_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Supabase's Use of Deno and Transformers:\n",
        "\n",
        "    Deno's Advantages:\n",
        "        Security: Deno is designed with security in mind. It operates in a secure sandbox environment, which means scripts can't access the network, file system, or environment variables without explicit permission. This feature aligns with Supabase's focus on building secure applications​1​.\n",
        "        Modern JavaScript Features: Deno supports modern JavaScript features out of the box. This makes it easier for developers to write and maintain their code, and it’s particularly useful when working with modern libraries and frameworks like Transformers.js​2​.\n",
        "        Built-in Tooling: Deno comes with built-in tooling like a test runner, code formatter, and bundler, which can simplify the development process, making it an attractive choice for building web applications quickly and efficiently​3​.\n",
        "\n",
        "    Transformers.js and Supabase/gte-small Model:\n",
        "        Transformers.js Compatibility: The Supabase/gte-small model is designed to be compatible with Transformers.js, which is a library for using transformer models in the browser. This compatibility allows for the easy generation of embeddings using the model directly within a web application environment​4​​5​.\n",
        "        Efficient Text Embedding Generation: The Supabase/gte-small model is utilized for generating text embeddings efficiently and is used in the workshop to facilitate the creation of a chat interface that can interact with documentations​6​.\n",
        "\n",
        "With Langchain's we Use of thenlper/gte-small Model:\n",
        "\n",
        "    General Text Embeddings (GTE): The thenlper/gte-small model, developed by Alibaba DAMO Academy, is based on the BERT framework and is trained on a large-scale corpus of relevant text pairs. This training enables the model to be highly effective in various text embedding tasks such as information retrieval, semantic textual similarity, and text reranking, which could be instrumental in LangChain's use case for text embeddings​7​.\n",
        "\n",
        "    Performance and Usage: In the Hugging Face description, it's noted that the thenlper/gte-small model has decent performance metrics on text embedding tasks when compared to other popular text embedding models. The provided code example also showcases how to utilize the model to generate text embeddings which can be beneficial in various natural language processing applications​7​.\n",
        "\n",
        "In summary, while Supabase leverages the modern features and security of Deno alongside the ease of embedding generation provided by Transformers.js and the Supabase/gte-small model, Langchain, on the other hand, might be harnessing the performance and wide domain coverage provided by the thenlper/gte-small model for its text embedding and NLP applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-10 08:50:06,170:INFO - Load pretrained SentenceTransformer: thenlper/gte-small\n"
          ]
        }
      ],
      "source": [
        "model_name = \"thenlper/gte-small\"\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "hf = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "SUPABASE_URL = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
        "SUPABASE_KEY = os.getenv(\"NEXT_PUBLIC_SUPABASE_ANON_KEY\")\n",
        "\n",
        "supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-10 08:54:12,097:WARNING - Created a chunk of size 1205, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,097:WARNING - Created a chunk of size 1216, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,098:WARNING - Created a chunk of size 2518, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,098:WARNING - Created a chunk of size 2569, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,098:WARNING - Created a chunk of size 1196, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,098:WARNING - Created a chunk of size 2062, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,099:WARNING - Created a chunk of size 1498, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,099:WARNING - Created a chunk of size 1525, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,099:WARNING - Created a chunk of size 1606, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,099:WARNING - Created a chunk of size 1014, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,100:WARNING - Created a chunk of size 1839, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,100:WARNING - Created a chunk of size 1225, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,100:WARNING - Created a chunk of size 1257, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,100:WARNING - Created a chunk of size 1490, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,101:WARNING - Created a chunk of size 1450, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,101:WARNING - Created a chunk of size 1022, which is longer than the specified 1000\n",
            "2023-10-10 08:54:12,101:WARNING - Created a chunk of size 1029, which is longer than the specified 1000\n"
          ]
        }
      ],
      "source": [
        "raw_documents = TextLoader('../../sample-files/roman-empire-1.md').load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(raw_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 2/2 [00:09<00:00,  5.00s/it]\n",
            "2023-10-10 10:25:48,613:INFO - HTTP Request: POST http://localhost:54321/rest/v1/langchain_documents \"HTTP/1.1 201 Created\"\n"
          ]
        }
      ],
      "source": [
        "vector_store = SupabaseVectorStore.from_documents(\n",
        "    documents, \n",
        "    hf, \n",
        "    client=supabase_client, \n",
        "    table_name=\"langchain_documents\", \n",
        "    query_name=\"match_langchain_documents_mmr\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"Who was the first emperor of the Roman Empire?\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Maximal Marginal Relevance Searches\n",
        "This section goes over different options for how to use SupabaseVectorStore as a retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_type=\"mmr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.46it/s]\n",
            "2023-10-10 10:25:58,102:INFO - HTTP Request: POST http://localhost:54321/rest/v1/rpc/match_langchain_documents_mmr?limit=20 \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "matched_docs = retriever.get_relevant_documents(query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "## Document 0\n",
            "\n",
            "# Roman Empire\n",
            "\n",
            "## Document 1\n",
            "\n",
            "Rome had begun expanding shortly after the founding of the [Roman Republic](/wiki/Roman_Republic 'Roman Republic') in the 6th century BC, though not outside the Italian peninsula until the 3rd century BC. Thus, it was an \\\"empire\\\" (a great power) long before it had an emperor. The Republic was not a nation-state in the modern sense, but a network of self-ruled towns (with varying degrees of independence from the [Senate](/wiki/Roman_Senate 'Roman Senate')) and provinces administered by military commanders. It was governed by annually elected [magistrates](/wiki/Roman_magistrate 'Roman magistrate') ([Roman consuls](/wiki/Roman_consul 'Roman consul') above all) in conjunction with the Senate. The 1st century BC was a time of political and military upheaval, which ultimately led to rule by emperors. The consuls\\' military power rested in the Roman legal concept of _[imperium](/wiki/Imperium 'Imperium')_, meaning \\\"command\\\" (though typically in a military sense). Occasionally, successful consuls were given the honorary title _[imperator](/wiki/Imperator 'Imperator')_ (commander); this is the origin of the word _emperor_, since this title was always bestowed to the early emperors.\n",
            "\n",
            "## Document 2\n",
            "\n",
            "Diocletian divided the empire into four regions, each ruled by a separate [tetrarch](/wiki/Tetrarchy 'Tetrarchy'). Confident that he fixed the disorder plaguing Rome, he abdicated along with his co-emperor, but the Tetrarchy [collapsed shortly after](/wiki/Civil_wars_of_the_Tetrarchy 'Civil wars of the Tetrarchy'). Order was eventually restored by [Constantine the Great](/wiki/Constantine_the_Great 'Constantine the Great'), who became the first emperor to [convert to Christianity](/wiki/Constantine_the_Great_and_Christianity 'Constantine the Great and Christianity'), and who established [Constantinople](/wiki/Constantinople 'Constantinople') as the new capital of the Eastern Empire. During the decades of the [Constantinian](/wiki/Constantinian_dynasty 'Constantinian dynasty') and [Valentinian](/wiki/Valentinian_dynasty 'Valentinian dynasty') dynasties, the empire was divided along an east--west axis, with dual power centres in Constantinople and Rome. [Julian](</wiki/Julian_(emperor)> 'Julian (emperor)'), who under the influence of his adviser [Mardonius](</wiki/Mardonius_(philosopher)> 'Mardonius (philosopher)') attempted to restore [Classical Roman](/wiki/Religion_in_ancient_Rome 'Religion in ancient Rome') and [Hellenistic religion](/wiki/Hellenistic_religion 'Hellenistic religion'), only briefly interrupted the succession of Christian emperors. [Theodosius I](/wiki/Theodosius_I 'Theodosius I'), the last emperor to rule over both East and West, died in 395 after making Christianity the [state religion](/wiki/State_church_of_the_Roman_Empire 'State church of the Roman Empire').\n",
            "\n",
            "## Document 3\n",
            "\n",
            "The 200 years that began with Augustus\\'s rule is traditionally regarded as the _[Pax Romana](/wiki/Pax_Romana 'Pax Romana')_ (\\\"Roman Peace\\\"). The cohesion of the empire was furthered by a degree of social stability and economic prosperity that Rome had never before experienced. Uprisings in the provinces were infrequent and put down \\\"mercilessly and swiftly\\\". The success of Augustus in establishing principles of dynastic succession was limited by his outliving a number of talented potential heirs. The [Julio-Claudian dynasty](/wiki/Julio-Claudian_dynasty 'Julio-Claudian dynasty') lasted for four more emperors---[Tiberius](/wiki/Tiberius 'Tiberius'), [Caligula](/wiki/Caligula 'Caligula'), [Claudius](/wiki/Claudius 'Claudius'), and [Nero](/wiki/Nero 'Nero')---before it yielded in 69 AD to the strife-torn [Year of the Four Emperors](/wiki/Year_of_the_Four_Emperors 'Year of the Four Emperors'), from which [Vespasian](/wiki/Vespasian 'Vespasian') emerged as victor. Vespasian became the founder of the brief [Flavian dynasty](/wiki/Flavian_dynasty 'Flavian dynasty'), followed by the [Nerva--Antonine dynasty](/wiki/Nerva%E2%80%93Antonine_dynasty 'Nerva–Antonine dynasty') which produced the \\\"[Five Good Emperors](/wiki/Five_Good_Emperors 'Five Good Emperors')\\\": [Nerva](/wiki/Nerva 'Nerva'), [Trajan](/wiki/Trajan 'Trajan'), [Hadrian](/wiki/Hadrian 'Hadrian'), [Antoninus Pius](/wiki/Antoninus_Pius 'Antoninus Pius'), and [Marcus Aurelius](/wiki/Marcus_Aurelius 'Marcus Aurelius').\n"
          ]
        }
      ],
      "source": [
        "for i, d in enumerate(matched_docs):\n",
        "    print(f\"\\n## Document {i}\\n\")\n",
        "    print(d.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents.agent_toolkits import create_retriever_tool\n",
        "\n",
        "tool = create_retriever_tool(\n",
        "    retriever, \n",
        "    \"search_about_roman_empire\",\n",
        "    \"Searches and returns documents regarding the roman empire.\"\n",
        ")\n",
        "tools = [tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(temperature = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_executor = create_conversational_retrieval_agent(llm, tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `search_about_roman_empire` with `{'query': 'roman empire'}`\n",
            "\n",
            "\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.00it/s]\n",
            "2023-10-10 10:26:32,100:INFO - HTTP Request: POST http://localhost:54321/rest/v1/rpc/match_langchain_documents_mmr?limit=20 \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36;1m\u001b[1;3m[Document(page_content='# Roman Empire', metadata={'source': '../../sample-files/roman-empire-1.md'}), Document(page_content=\"The **Roman Empire** was the post-[Republican](/wiki/Roman_Republic 'Roman Republic') state of [ancient Rome](/wiki/Ancient_Rome 'Ancient Rome') and is generally understood to mean the period, and the territory ruled by the [Romans](/wiki/Roman_people 'Roman people') following [Octavian](/wiki/Octavian 'Octavian')\\\\'s assumption of sole rule under the [Principate](/wiki/Principate 'Principate') in 31 BC. It included territory around the [Mediterranean](/wiki/Mediterranean_Sea 'Mediterranean Sea') in [Europe](/wiki/Europe 'Europe'), [North Africa](/wiki/North_Africa 'North Africa'), and [Western Asia](/wiki/Western_Asia 'Western Asia'), eventually extending as far north as Northern Europe, and was ruled by [emperors](/wiki/Roman_emperor 'Roman emperor'). The adoption of Christianity as the [state church](/wiki/Christianity_as_the_Roman_state_religion 'Christianity as the Roman state religion') in 380 and the [fall of the Western Roman Empire](/wiki/Fall_of_the_Western_Roman_Empire 'Fall of the Western Roman Empire') conventionally marks the end of [classical antiquity](/wiki/Classical_antiquity 'Classical antiquity') and the beginning of the [Middle Ages](/wiki/Middle_Ages 'Middle Ages').\", metadata={'source': '../../sample-files/roman-empire-1.md'}), Document(page_content='The Roman Empire was [one of the largest](/wiki/List_of_largest_empires \\'List of largest empires\\') in history, with contiguous territories throughout Europe, North Africa, and the Middle East. The Latin phrase _imperium sine fine_ (\\\\\"empire without end\\\\\") expressed the ideology that neither time nor space limited the Empire. In [Virgil](/wiki/Virgil \\'Virgil\\')\\\\\\'s _[Aeneid](/wiki/Aeneid \\'Aeneid\\'),_ limitless empire is said to be granted to the Romans by [Jupiter](</wiki/Jupiter_(mythology)> \\'Jupiter (mythology)\\'). This claim of universal dominion was renewed when the Empire came under Christian rule in the 4th century. In addition to annexing large regions, the Romans directly altered their geography, for example [cutting down entire forests](/wiki/Deforestation_during_the_Roman_period \\'Deforestation during the Roman period\\').', metadata={'source': '../../sample-files/roman-empire-1.md'}), Document(page_content=\"The [Western Roman Empire](/wiki/Western_Roman_Empire 'Western Roman Empire') began to [disintegrate](/wiki/Fall_of_the_Western_Roman_Empire 'Fall of the Western Roman Empire') in the early 5th century. The Romans were successful in fighting off all invaders, most famously [Attila](/wiki/Attila 'Attila'), but the empire had [assimilated so many Germanic peoples](/wiki/Migration_Period 'Migration Period') of dubious loyalty to Rome that the empire started to dismember itself. [Most chronologies](/wiki/Fall_of_the_Western_Roman_Empire 'Fall of the Western Roman Empire') place the end of the Western Roman Empire in 476, when [Romulus Augustulus](/wiki/Romulus_Augustulus 'Romulus Augustulus') was [forced to abdicate](/wiki/Deposition_of_Romulus_Augustulus 'Deposition of Romulus Augustulus') to the [Germanic](/wiki/Germanic_peoples 'Germanic peoples') warlord [Odoacer](/wiki/Odoacer 'Odoacer').\", metadata={'source': '../../sample-files/roman-empire-1.md'})]\u001b[0m\u001b[32;1m\u001b[1;3mThe Roman Empire was the post-Republican state of ancient Rome. It is generally understood to mean the period and the territory ruled by the Romans following Octavian's assumption of sole rule under the Principate in 31 BC. The empire included territory around the Mediterranean in Europe, North Africa, and Western Asia, eventually extending as far north as Northern Europe. It was ruled by emperors. The adoption of Christianity as the state church in 380 and the fall of the Western Roman Empire conventionally marks the end of classical antiquity and the beginning of the Middle Ages.\n",
            "\n",
            "The Roman Empire was one of the largest empires in history, with contiguous territories throughout Europe, North Africa, and the Middle East. The ideology of the empire was expressed by the Latin phrase \"imperium sine fine\" (empire without end), which meant that neither time nor space limited the Empire. The claim of universal dominion was renewed when the Empire came under Christian rule in the 4th century. The Romans also directly altered the geography of the regions they conquered, such as cutting down entire forests.\n",
            "\n",
            "The Western Roman Empire began to disintegrate in the early 5th century. Although the Romans were successful in fighting off invaders, the empire had assimilated many Germanic peoples of dubious loyalty to Rome, which led to its dismemberment. The end of the Western Roman Empire is usually placed in 476 when Romulus Augustulus was forced to abdicate to the Germanic warlord Odoacer.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "result = agent_executor({\"input\": \"Hello, I would like to know about the roman empire.\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mYes, there was a Stoic emperor in the Roman Empire. His name was Marcus Aurelius. He ruled as emperor from 161 to 180 AD. Marcus Aurelius is known for his philosophical writings, particularly his collection of personal reflections known as \"Meditations.\" In these writings, he explores Stoic principles and reflects on topics such as virtue, self-discipline, and the nature of the universe. Marcus Aurelius is considered one of the most famous Stoic philosophers and his writings continue to be studied and admired today.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "result = agent_executor({\"input\": \"You know some estoic emperor?\"})"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "OpenAIWhisper",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "68796c4a74138b7d74b1ad1d89abe16eb1cdb3a820722abb0431af506d216224"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
